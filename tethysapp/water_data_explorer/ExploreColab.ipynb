{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExploreColab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5O5d0xtxJ-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## DEFINE VARIABLES ##\n",
        "hs_url = \"http://hydroportal.cuahsi.org/para_la_naturaleza/cuahsi_1_1.asmx?WSDL\"\n",
        "hs_name = \"Para la Naturaleza\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKPQSMRcHNsy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "outputId": "94844968-e6a8-4221-f3e5-9707b022555e"
      },
      "source": [
        "!pip install xmltodict\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install owslib\n",
        "!pip install suds-py3\n",
        "!pip install folium\n",
        "!pip install plotly"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.6/dist-packages (0.12.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Requirement already satisfied: owslib in /usr/local/lib/python3.6/dist-packages (0.20.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from owslib) (2018.9)\n",
            "Requirement already satisfied: requests>=1.0 in /usr/local/lib/python3.6/dist-packages (from owslib) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=1.5 in /usr/local/lib/python3.6/dist-packages (from owslib) (2.8.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from owslib) (3.13)\n",
            "Requirement already satisfied: pyproj>=2 in /usr/local/lib/python3.6/dist-packages (from owslib) (2.6.1.post1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=1.0->owslib) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=1.0->owslib) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=1.0->owslib) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=1.0->owslib) (3.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=1.5->owslib) (1.15.0)\n",
            "Requirement already satisfied: suds-py3 in /usr/local/lib/python3.6/dist-packages (1.4.1.0)\n",
            "Requirement already satisfied: folium in /usr/local/lib/python3.6/dist-packages (0.8.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from folium) (2.11.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from folium) (1.18.5)\n",
            "Requirement already satisfied: branca>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from folium) (0.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from folium) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from folium) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->folium) (1.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->folium) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->folium) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->folium) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->folium) (2020.6.20)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (4.4.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly) (1.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pCqiHUCCq82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##IMPORT THE DEPENDENCIES\n",
        "import xmltodict\n",
        "import json\n",
        "import calendar\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import folium\n",
        "import plotly.graph_objects as go\n",
        "import xml.etree.ElementTree as ET\n",
        "from owslib.waterml.wml11 import WaterML_1_1 as wml11\n",
        "from suds.client import Client  # For parsing WaterML/XML\n",
        "from json import dumps, loads\n",
        "from datetime import datetime"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAV_SRM3E-al",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parseJSON(json):\n",
        "    hs_sites = []\n",
        "    sites_object = None\n",
        "    # This is to handle the WMO la Plata endpoints ##\n",
        "\n",
        "    if \"Site\" in json:\n",
        "        sites_object = json['Site']\n",
        "        # If statement is executed for multiple sites within the HydroServer, if there is a single site then it goes to the else statement\n",
        "        # Parse through the HydroServer and each site with its metadata as a\n",
        "        # dictionary object to the hs_sites list\n",
        "        if type(sites_object) is list:\n",
        "            for site in sites_object:\n",
        "                hs_json = {}\n",
        "                latitude = site['Latitude']\n",
        "                longitude = site['Longitude']\n",
        "                site_name = site['SiteName']\n",
        "                site_name = site_name.encode(\"utf-8\")\n",
        "                network = site[\"servURL\"]\n",
        "                sitecode = site['SiteCode']\n",
        "\n",
        "                hs_json[\"sitename\"] = site_name.decode(\"UTF-8\")\n",
        "                hs_json[\"latitude\"] = latitude\n",
        "                hs_json[\"longitude\"] = longitude\n",
        "                hs_json[\"sitecode\"] = sitecode\n",
        "                hs_json[\"network\"] = network\n",
        "                hs_json[\"service\"] = \"SOAP\"\n",
        "                hs_sites.append(hs_json)\n",
        "        else:\n",
        "            hs_json = {}\n",
        "            latitude = site['Latitude']\n",
        "            longitude = site['Longitude']\n",
        "            site_name = site['SiteName']\n",
        "            site_name = site_name.encode(\"utf-8\")\n",
        "            network = site[\"servURL\"]\n",
        "            sitecode = site['SiteCode']\n",
        "\n",
        "            hs_json[\"sitename\"] = site_name.decode(\"UTF-8\")\n",
        "            hs_json[\"latitude\"] = latitude\n",
        "            hs_json[\"longitude\"] = longitude\n",
        "            hs_json[\"sitecode\"] = sitecode\n",
        "            hs_json[\"network\"] = network\n",
        "            hs_json[\"service\"] = \"SOAP\"\n",
        "            hs_sites.append(hs_json)\n",
        "\n",
        "    if \"sitesResponse\" in json:\n",
        "        sites_object = json['sitesResponse']['site']\n",
        "\n",
        "        # If statement is executed for multiple sites within the HydroServer, if there is a single site then it goes to the else statement\n",
        "        # Parse through the HydroServer and each site with its metadata as a\n",
        "        # dictionary object to the hs_sites list\n",
        "        if type(sites_object) is list:\n",
        "            for site in sites_object:\n",
        "                hs_json = {}\n",
        "                latitude = site['siteInfo']['geoLocation'][\n",
        "                    'geogLocation']['latitude']\n",
        "                longitude = site['siteInfo']['geoLocation'][\n",
        "                    'geogLocation']['longitude']\n",
        "                site_name = site['siteInfo']['siteName']\n",
        "                site_name = site_name.encode(\"utf-8\")\n",
        "                network = site['siteInfo']['siteCode'][\"@network\"]\n",
        "                sitecode = site['siteInfo']['siteCode'][\"#text\"]\n",
        "\n",
        "                hs_json[\"sitename\"] = site_name.decode(\"UTF-8\")\n",
        "                hs_json[\"latitude\"] = latitude\n",
        "                hs_json[\"longitude\"] = longitude\n",
        "                hs_json[\"sitecode\"] = sitecode\n",
        "                hs_json[\"network\"] = network\n",
        "                hs_json[\"service\"] = \"SOAP\"\n",
        "                hs_sites.append(hs_json)\n",
        "        else:\n",
        "            hs_json = {}\n",
        "            latitude = sites_object['siteInfo'][\n",
        "                'geoLocation']['geogLocation']['latitude']\n",
        "            longitude = sites_object['siteInfo'][\n",
        "                'geoLocation']['geogLocation']['longitude']\n",
        "            site_name = sites_object['siteInfo']['siteName']\n",
        "            site_name = site_name.encode(\"utf-8\")\n",
        "            network = sites_object['siteInfo']['siteCode'][\"@network\"]\n",
        "            sitecode = sites_object['siteInfo']['siteCode'][\"#text\"]\n",
        "\n",
        "            hs_json[\"sitename\"] = site_name.decode(\"UTF-8\")\n",
        "            hs_json[\"latitude\"] = latitude\n",
        "            hs_json[\"longitude\"] = longitude\n",
        "            hs_json[\"sitecode\"] = sitecode\n",
        "            hs_json[\"network\"] = network\n",
        "            hs_json[\"service\"] = \"SOAP\"\n",
        "            hs_sites.append(hs_json)\n",
        "\n",
        "    return hs_sites\n",
        "\n",
        "\n",
        "def add_hs(url):\n",
        "    return_obj = {}\n",
        "    client = Client(url, timeout= 500)\n",
        "    # True Extent is on and necessary if the user is trying to add USGS or\n",
        "    # Get a list of all the sites and their respective lat lon.\n",
        "    sites = client.service.GetSites('[:]')\n",
        "    sites_json={}\n",
        "    if isinstance(sites, str):\n",
        "        sites_dict = xmltodict.parse(sites)\n",
        "        sites_json_object = json.dumps(sites_dict)\n",
        "        sites_json = json.loads(sites_json_object)\n",
        "    else:\n",
        "        sites_json_object = suds_to_json(sites)\n",
        "        sites_json = json.loads(sites_json_object)\n",
        "\n",
        "    sites_object = parseJSON(sites_json)\n",
        " \n",
        "    return_obj['siteInfo'] = sites_object\n",
        "    return return_obj\n",
        "\n",
        "def get_lats_lngs(objSites):\n",
        "    sites = objSites['siteInfo']\n",
        "    sitesLoc = []\n",
        "    names = []\n",
        "    for site in sites:\n",
        "      sitesLoc.append([float(site['latitude']) , float(site['longitude'])])\n",
        "      names.append(site['sitename'])\n",
        "    return [sitesLoc,names]\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vj06tE8DGvhh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0ec11f81-1c39-44da-b864-59b8e46b2932"
      },
      "source": [
        "sitesResponse = add_hs(hs_url)\n",
        "sites = sitesResponse['siteInfo'] ## array containing the sites\n",
        "print(sites)\n",
        "\n",
        "##taking the lat, lng, and names from the sites\n",
        "sitesLocations,sitesNames = get_lats_lngs(sitesResponse)\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'sitename': 'Río Toro Negro', 'latitude': '18.28559', 'longitude': '-66.4903', 'sitecode': 'Rio_Toro_Negro', 'network': 'Para_La_Naturaleza', 'service': 'SOAP'}, {'sitename': 'Quebrada Batista', 'latitude': '18.19699', 'longitude': '-66.32992', 'sitecode': 'Quebrada_Batista', 'network': 'Para_La_Naturaleza', 'service': 'SOAP'}, {'sitename': 'Río Grande de Manatí', 'latitude': '18.2144', 'longitude': '-66.28665', 'sitecode': 'Rio_Grande_de_Manati', 'network': 'Para_La_Naturaleza', 'service': 'SOAP'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR7KNWzsNHGB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "86c90747-7d5e-4959-a247-4174c056b784"
      },
      "source": [
        "# Create a map using Stamen Terrain, centered on Boulder, CO\n",
        "m = folium.Map(location=[40.0150, -105.2705], \n",
        "              tiles = 'Stamen Terrain')\n",
        "\n",
        "# Add marker for Boulder, CO\n",
        "for ind in range(len(sitesLocations)):\n",
        "  folium.Marker(\n",
        "      location= sitesLocations[ind], # coordinates for the marker (Earth Lab at CU Boulder)\n",
        "      popup= sitesNames[ind], # pop-up label for the marker\n",
        "      icon=folium.Icon()\n",
        "  ).add_to(m)\n",
        "\n",
        "# Display m\n",
        "m.fit_bounds(sitesLocations)\n",
        "m"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe src=\"about:blank\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" data-html=<!DOCTYPE html>
<head>    
    <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
    <script>L_PREFER_CANVAS=false; L_NO_TOUCH=false; L_DISABLE_3D=false;</script>
    <script src="https://cdn.jsdelivr.net/npm/leaflet@1.4.0/dist/leaflet.js"></script>
    <script src="https://code.jquery.com/jquery-1.12.4.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.4.0/dist/leaflet.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap-theme.min.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css"/>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css"/>
    <link rel="stylesheet" href="https://rawcdn.githack.com/python-visualization/folium/master/folium/templates/leaflet.awesome.rotate.css"/>
    <style>html, body {width: 100%;height: 100%;margin: 0;padding: 0;}</style>
    <style>#map {position:absolute;top:0;bottom:0;right:0;left:0;}</style>
    
    <meta name="viewport" content="width=device-width,
        initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <style>#map_d4819343c7a549d9b6e9b0fef7398e85 {
        position: relative;
        width: 100.0%;
        height: 100.0%;
        left: 0.0%;
        top: 0.0%;
        }
    </style>
</head>
<body>    
    
    <div class="folium-map" id="map_d4819343c7a549d9b6e9b0fef7398e85" ></div>
</body>
<script>    
    
    
        var bounds = null;
    

    var map_d4819343c7a549d9b6e9b0fef7398e85 = L.map(
        'map_d4819343c7a549d9b6e9b0fef7398e85', {
        center: [40.015, -105.2705],
        zoom: 10,
        maxBounds: bounds,
        layers: [],
        worldCopyJump: false,
        crs: L.CRS.EPSG3857,
        zoomControl: true,
        });


    
    var tile_layer_9066da6cf7684b4c8bba4ca7aa32da2f = L.tileLayer(
        'https://stamen-tiles-{s}.a.ssl.fastly.net/terrain/{z}/{x}/{y}.jpg',
        {
        "attribution": null,
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_d4819343c7a549d9b6e9b0fef7398e85);
    
        var marker_e3595562b92e413cb786126d92c2ed0a = L.marker(
            [18.28559, -66.4903],
            {
                icon: new L.Icon.Default(),
                }
            ).addTo(map_d4819343c7a549d9b6e9b0fef7398e85);
        
    

                var icon_609feb583df64fd58254a01445e5d89e = L.AwesomeMarkers.icon({
                    icon: 'info-sign',
                    iconColor: 'white',
                    markerColor: 'blue',
                    prefix: 'glyphicon',
                    extraClasses: 'fa-rotate-0'
                    });
                marker_e3595562b92e413cb786126d92c2ed0a.setIcon(icon_609feb583df64fd58254a01445e5d89e);
            
    
            var popup_7c300a1eae9b4cb7acb0a5972abd96ef = L.popup({maxWidth: '100%'
            
            });

            
                var html_acfd115842074c8a9d6949d697433d14 = $(`<div id="html_acfd115842074c8a9d6949d697433d14" style="width: 100.0%; height: 100.0%;">Río Toro Negro</div>`)[0];
                popup_7c300a1eae9b4cb7acb0a5972abd96ef.setContent(html_acfd115842074c8a9d6949d697433d14);
            

            marker_e3595562b92e413cb786126d92c2ed0a.bindPopup(popup_7c300a1eae9b4cb7acb0a5972abd96ef)
            ;

            
        
    
        var marker_385a41766d94472782e46a946132fb45 = L.marker(
            [18.19699, -66.32992],
            {
                icon: new L.Icon.Default(),
                }
            ).addTo(map_d4819343c7a549d9b6e9b0fef7398e85);
        
    

                var icon_e861bb6b51164f83a467053b2a8bcacf = L.AwesomeMarkers.icon({
                    icon: 'info-sign',
                    iconColor: 'white',
                    markerColor: 'blue',
                    prefix: 'glyphicon',
                    extraClasses: 'fa-rotate-0'
                    });
                marker_385a41766d94472782e46a946132fb45.setIcon(icon_e861bb6b51164f83a467053b2a8bcacf);
            
    
            var popup_c72627ef723e4b1088e6151345a9ed08 = L.popup({maxWidth: '100%'
            
            });

            
                var html_ff78e3e28ea048f4aeb554cc6cf0ac1c = $(`<div id="html_ff78e3e28ea048f4aeb554cc6cf0ac1c" style="width: 100.0%; height: 100.0%;">Quebrada Batista</div>`)[0];
                popup_c72627ef723e4b1088e6151345a9ed08.setContent(html_ff78e3e28ea048f4aeb554cc6cf0ac1c);
            

            marker_385a41766d94472782e46a946132fb45.bindPopup(popup_c72627ef723e4b1088e6151345a9ed08)
            ;

            
        
    
        var marker_c72e90ce4bb041b89dfb3ea2d622214b = L.marker(
            [18.2144, -66.28665],
            {
                icon: new L.Icon.Default(),
                }
            ).addTo(map_d4819343c7a549d9b6e9b0fef7398e85);
        
    

                var icon_01088951729c4d7fa7b0983b9713f7f5 = L.AwesomeMarkers.icon({
                    icon: 'info-sign',
                    iconColor: 'white',
                    markerColor: 'blue',
                    prefix: 'glyphicon',
                    extraClasses: 'fa-rotate-0'
                    });
                marker_c72e90ce4bb041b89dfb3ea2d622214b.setIcon(icon_01088951729c4d7fa7b0983b9713f7f5);
            
    
            var popup_50145ce690774311a6bab0f1ce9882d9 = L.popup({maxWidth: '100%'
            
            });

            
                var html_fd7140a662b3435c930f639e71740eee = $(`<div id="html_fd7140a662b3435c930f639e71740eee" style="width: 100.0%; height: 100.0%;">Río Grande de Manatí</div>`)[0];
                popup_50145ce690774311a6bab0f1ce9882d9.setContent(html_fd7140a662b3435c930f639e71740eee);
            

            marker_c72e90ce4bb041b89dfb3ea2d622214b.bindPopup(popup_50145ce690774311a6bab0f1ce9882d9)
            ;

            
        
    
                

                map_d4819343c7a549d9b6e9b0fef7398e85.fitBounds(
                    [[18.28559, -66.4903], [18.19699, -66.32992], [18.2144, -66.28665]],
                    {}
                    );
            
</script> onload=\"this.contentDocument.open();this.contentDocument.write(atob(this.getAttribute('data-html')));this.contentDocument.close();\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ],
            "text/plain": [
              "<folium.folium.Map at 0x7fd4981ade10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bPfXvzJKWP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Get the variables for the hydroserver\n",
        "def GetVariables():  \n",
        "  client = Client(url = hs_url, timeout= 500)\n",
        "\n",
        "  keywords = client.service.GetVariables('[:]')\n",
        "\n",
        "  keywords_dict = xmltodict.parse(keywords)\n",
        "  keywords_dict_object = json.dumps(keywords_dict)\n",
        "\n",
        "  keywords_json = json.loads(keywords_dict_object)\n",
        "  array_variables=keywords_json['variablesResponse']['variables']['variable']\n",
        "  array_keywords_hydroserver=[]\n",
        "\n",
        "  if isinstance(array_variables,type([])):\n",
        "      for words in array_variables:\n",
        "          array_keywords_hydroserver.append(words['variableName'])\n",
        "\n",
        "  if isinstance(array_variables,dict):\n",
        "      array_keywords_hydroserver.append(array_variables['variableName'])\n",
        "\n",
        "  return array_keywords_hydroserver"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfA36Xp28WAQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a47dedd4-5a9a-4cfd-a2b3-8fd4eb1471e9"
      },
      "source": [
        "variables_hs = GetVariables()\n",
        "print(\"The variables available in the hydroserver are:\")\n",
        "print(variables_hs)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The variables available in the hydroserver are:\n",
            "['Water depth, averaged', 'Discharge', 'Velocity']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NbcYnAZOHU3",
        "colab_type": "text"
      },
      "source": [
        "# **[Get info from a specific site.](https://)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtNKcBfFOroi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "31da70ff-3ddc-4840-de91-c93012ac46db"
      },
      "source": [
        "### If you want a different site just change the name.\n",
        "chosen_site_name = \"Río Toro Negro\"\n",
        "chosen_site_dict = {}\n",
        "\n",
        "for site in sites:\n",
        "    if site['sitename'] == chosen_site_name:\n",
        "        chosen_site_dict = site\n",
        "        break\n",
        "else:\n",
        "    site = None\n",
        "\n",
        "print(chosen_site_dict)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'sitename': 'Río Toro Negro', 'latitude': '18.28559', 'longitude': '-66.4903', 'sitecode': 'Rio_Toro_Negro', 'network': 'Para_La_Naturaleza', 'service': 'SOAP'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9234PsIMsE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Get Site Info ##\n",
        "def get_site_info(chosen_site_dict):\n",
        "    site_code =  chosen_site_dict['sitecode']\n",
        "    network = chosen_site_dict['network']\n",
        "    site_desc = network + ':' + site_code\n",
        "\n",
        "    client = Client(hs_url)\n",
        "\n",
        "    keywords = client.service.GetVariables('[:]')\n",
        "    keywords_dict = xmltodict.parse(keywords)\n",
        "    keywords_dict_object = json.dumps(keywords_dict)\n",
        "\n",
        "    keywords_json = json.loads(keywords_dict_object)\n",
        "\n",
        "    site_info_Mc = client.service.GetSiteInfo(site_desc)\n",
        "    site_info_Mc_dict = xmltodict.parse(site_info_Mc)\n",
        "    site_info_Mc_json_object = json.dumps(site_info_Mc_dict)\n",
        "    site_info_Mc_json = json.loads(site_info_Mc_json_object)\n",
        "\n",
        "    object_methods= site_info_Mc_json['sitesResponse']['site']['seriesCatalog']['series']\n",
        "\n",
        "    object_with_methods_and_variables = {}\n",
        "    object_with_descriptions_and_variables = {}\n",
        "    object_with_time_and_variables = {}\n",
        "    if(isinstance(object_methods,(dict))):\n",
        "        variable_name_ = object_methods['variable']['variableName']\n",
        "        if 'method' in object_methods:\n",
        "            object_with_methods_and_variables[variable_name_]= object_methods['method']['@methodID']\n",
        "        else:\n",
        "            object_with_methods_and_variables[variable_name_]= None\n",
        "        object_with_descriptions_and_variables[variable_name_]= object_methods['source'];\n",
        "        object_with_time_and_variables[variable_name_]= object_methods['variableTimeInterval'];\n",
        "    else:\n",
        "        for object_method in object_methods:\n",
        "            variable_name_ = object_method['variable']['variableName']\n",
        "            if 'method' in object_method:\n",
        "                object_with_methods_and_variables[variable_name_]= object_method['method']['@methodID']\n",
        "            else:\n",
        "                object_with_methods_and_variables[variable_name_]= None\n",
        "            object_with_descriptions_and_variables[variable_name_]= object_method['source'];\n",
        "            object_with_time_and_variables[variable_name_]= object_method['variableTimeInterval'];\n",
        "\n",
        "    array_variables=keywords_json['variablesResponse']['variables']['variable']\n",
        "    array_keywords_hydroserver=[]\n",
        "    array_variables_codes = []\n",
        "    array_variables_lengths = []\n",
        "    length_values = 0\n",
        "    if isinstance(array_variables,type([])):\n",
        "        for words in array_variables:\n",
        "\n",
        "            variable_text = words['variableName']\n",
        "            code_variable = words['variableCode']['#text']\n",
        "            start_date = \"\"\n",
        "            end_date = \"\"\n",
        "            variable_desc = network + ':' + code_variable\n",
        "            try:\n",
        "                values = client.service.GetValues(\n",
        "                    site_desc, variable_desc, start_date, end_date, \"\")\n",
        "\n",
        "                values_dict = xmltodict.parse(values)  # Converting xml to dict\n",
        "                values_json_object = json.dumps(values_dict)\n",
        "                values_json = json.loads(values_json_object)\n",
        "                if 'timeSeriesResponse' in values_json:\n",
        "                    times_series = values_json['timeSeriesResponse'][\n",
        "                        'timeSeries']  # Timeseries object for the variable\n",
        "                    if times_series['values'] is not None:\n",
        "                        length_values= len(times_series['values']['value'])\n",
        "                    else:\n",
        "                        length_values = 0\n",
        "                else:\n",
        "                    times_series = values_json['wml1:timeSeriesResponse'][\n",
        "                        'wml1:timeSeries']  # Timeseries object for the variable\n",
        "                    if times_series['wml1:values'] is not None:\n",
        "                        length_values= len(times_series['wml1:values']['wml1:value'])\n",
        "                    else:\n",
        "                        length_values = 0\n",
        "\n",
        "                array_variables_lengths.append(length_values)\n",
        "                array_keywords_hydroserver.append(words['variableName'])\n",
        "                array_variables_codes.append(words['variableCode']['#text'])\n",
        "            except Exception as e:\n",
        "                print(\"OOPS\",e.__class__)\n",
        "    if isinstance(array_variables,dict):\n",
        "        variable_text = array_variables['variableName']\n",
        "        code_variable = array_variables['variableCode']['#text']\n",
        "        start_date = \"\"\n",
        "        end_date = \"\"\n",
        "        variable_desc = network + ':' + code_variable\n",
        "        try:\n",
        "            values = client.service.GetValues(\n",
        "                site_desc, variable_desc, start_date, end_date, \"\")\n",
        "\n",
        "            values_dict = xmltodict.parse(values)  # Converting xml to dict\n",
        "            values_json_object = json.dumps(values_dict)\n",
        "            values_json = json.loads(values_json_object)\n",
        "            if 'timeSeriesResponse' in values_json:\n",
        "                times_series = values_json['timeSeriesResponse'][\n",
        "                    'timeSeries']  # Timeseries object for the variable\n",
        "                if times_series['values'] is not None:\n",
        "                    length_values= len(times_series['values']['value'])\n",
        "                else:\n",
        "                    length_values = 0\n",
        "            else:\n",
        "                times_series = values_json['wml1:timeSeriesResponse'][\n",
        "                    'wml1:timeSeries']  # Timeseries object for the variable\n",
        "                if times_series['wml1:values'] is not None:\n",
        "                    length_values= len(times_series['wml1:values']['wml1:value'])\n",
        "                else:\n",
        "                    length_values = 0\n",
        "\n",
        "\n",
        "            array_variables_lengths.append(length_values)\n",
        "\n",
        "            array_keywords_hydroserver.append(array_variables['variableName'])\n",
        "            array_variables_codes.append(array_variables['variableCode']['#text'])\n",
        "        except Exception as e:\n",
        "            print(\"OOPS\",e.__class__)\n",
        "    return_obj={}\n",
        "    return_obj['variables_names']=array_keywords_hydroserver\n",
        "    return_obj['variables_codes']=array_variables_codes\n",
        "    return_obj['variables_counts'] = array_variables_lengths\n",
        "    return_obj['variables_methodsIDs']= object_with_methods_and_variables\n",
        "    return_obj['variables_description'] = object_with_descriptions_and_variables\n",
        "    return_obj['variables_times_series_description'] = object_with_time_and_variables\n",
        "    return_obj['fullsiteInfo']= site_info_Mc_json\n",
        "\n",
        "    return return_obj\n"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqqY-xeTSjbF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "571b6461-7937-4ab0-b6d1-09af49aef0e4"
      },
      "source": [
        "info_site = get_site_info(chosen_site_dict)\n",
        "## The name of the variables in the site\n",
        "print(\"The name of the variables in the site \\n\", info_site['variables_names'])\n",
        "\n",
        "## The variables codes in the site\n",
        "print(\"The variables codes in the site \\n\" , info_site['variables_codes'])\n",
        "\n",
        "## The number of values in each variable in the site\n",
        "print(\"The number of values in each variable in the site \\n\", info_site['variables_counts'])\n",
        "\n",
        "## The method ID of each variable in the site\n",
        "print(\"The method ID of each variable in the site \\n\", info_site['variables_methodsIDs'])\n",
        "\n",
        "##The description of all the varaibles in the site\n",
        "print(\"The method ID of each variable in the site \\n\", info_site['variables_description'])\n",
        "\n",
        "##The description of all the time series of each variable in the site\n",
        "print(\"The description of all the time series of each variable in the site \\n\", info_site['variables_times_series_description'])\n",
        "\n",
        "##The fullSite Information about the site\n",
        "\n",
        "print(\"The fullSite Information about the site \\n\",info_site['siteInfo'])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The name of the variables in the site \n",
            " ['Water depth, averaged', 'Discharge', 'Velocity']\n",
            "The variables codes in the site \n",
            " ['Average_Stream_Depth', 'Total_Flow', 'Average_Stream_Velocity']\n",
            "The number of values in each variable in the site \n",
            " [21, 21, 21]\n",
            "The method ID of each variable in the site \n",
            " {'Water depth, averaged': '1', 'Discharge': '2', 'Velocity': '3'}\n",
            "The method ID of each variable in the site \n",
            " {'Water depth, averaged': {'@sourceID': '1', 'organization': 'Para La Naturaleza', 'sourceDescription': 'Para La Naturaleza and National Science Foundation (Grant No. 1223882) sponsored this Citizen Science project about the hydrology of three streams in the Rio Grande de Manatí Watershed in Puerto Rico.', 'citation': 'Para La Naturaleza NSF'}, 'Discharge': {'@sourceID': '1', 'organization': 'Para La Naturaleza', 'sourceDescription': 'Para La Naturaleza and National Science Foundation (Grant No. 1223882) sponsored this Citizen Science project about the hydrology of three streams in the Rio Grande de Manatí Watershed in Puerto Rico.', 'citation': 'Para La Naturaleza NSF'}, 'Velocity': {'@sourceID': '1', 'organization': 'Para La Naturaleza', 'sourceDescription': 'Para La Naturaleza and National Science Foundation (Grant No. 1223882) sponsored this Citizen Science project about the hydrology of three streams in the Rio Grande de Manatí Watershed in Puerto Rico.', 'citation': 'Para La Naturaleza NSF'}}\n",
            "The description of all the time series of each variable in the site \n",
            " {'Water depth, averaged': {'@xsi:type': 'TimeIntervalType', 'beginDateTime': '2013-08-03T09:00:00', 'endDateTime': '2015-05-02T09:00:00', 'beginDateTimeUTC': '2013-08-03T05:00:00', 'endDateTimeUTC': '2015-05-02T05:00:00'}, 'Discharge': {'@xsi:type': 'TimeIntervalType', 'beginDateTime': '2013-08-03T09:00:00', 'endDateTime': '2015-05-02T09:00:00', 'beginDateTimeUTC': '2013-08-03T05:00:00', 'endDateTimeUTC': '2015-05-02T05:00:00'}, 'Velocity': {'@xsi:type': 'TimeIntervalType', 'beginDateTime': '2013-08-03T09:00:00', 'endDateTime': '2015-05-02T09:00:00', 'beginDateTimeUTC': '2013-08-03T05:00:00', 'endDateTimeUTC': '2015-05-02T05:00:00'}}\n",
            "The fullSite Information about the site \n",
            " {'sitesResponse': {'@xmlns:gml': 'http://www.opengis.net/gml', '@xmlns:xlink': 'http://www.w3.org/1999/xlink', '@xmlns:xsd': 'http://www.w3.org/2001/XMLSchema', '@xmlns:xsi': 'http://www.w3.org/2001/XMLSchema-instance', '@xmlns:wtr': 'http://www.cuahsi.org/waterML/', '@xmlns': 'http://www.cuahsi.org/waterML/1.1/', 'queryInfo': {'creationTime': '2020-09-16T00:37:01.6225449+00:00', 'criteria': {'@MethodCalled': 'GetSiteInfo', 'parameter': {'@name': 'site', '@value': 'Para_La_Naturaleza:Rio_Toro_Negro'}}}, 'site': {'siteInfo': {'siteName': 'Río Toro Negro', 'siteCode': {'@network': 'Para_La_Naturaleza', '@siteID': '1', '#text': 'Rio_Toro_Negro'}, 'geoLocation': {'geogLocation': {'@xsi:type': 'LatLonPointType', '@srs': 'EPSG:26918', 'latitude': '18.28559', 'longitude': '-66.4903'}}, 'siteProperty': [{'@name': 'County', '#text': 'Unknown'}, {'@name': 'State', '#text': 'Unknown'}]}, 'seriesCatalog': {'@menuGroupName': '', '@serviceWsdl': 'http://hydroportal.cuahsi.org/Para_La_Naturaleza/cuahsi_1_1.asmx?WSDL', 'series': [{'variable': {'variableCode': {'@vocabulary': 'Para_La_Naturaleza', '@default': 'true', '@variableID': '1', '#text': 'Average_Stream_Depth'}, 'variableName': 'Water depth, averaged', 'valueType': 'Field Observation', 'dataType': 'Average', 'generalCategory': 'Hydrology', 'sampleMedium': 'Surface water', 'unit': {'unitName': 'meter', 'unitType': 'Length', 'unitAbbreviation': 'm', 'unitCode': '52'}, 'noDataValue': '-9999', 'timeScale': {'@isRegular': 'true', 'unit': {'unitName': 'meter', 'unitType': 'Length', 'unitAbbreviation': 'm', 'unitCode': '52'}, 'timeSupport': '1'}, 'speciation': 'Not Applicable'}, 'valueCount': '21', 'variableTimeInterval': {'@xsi:type': 'TimeIntervalType', 'beginDateTime': '2013-08-03T09:00:00', 'endDateTime': '2015-05-02T09:00:00', 'beginDateTimeUTC': '2013-08-03T05:00:00', 'endDateTimeUTC': '2015-05-02T05:00:00'}, 'method': {'@methodID': '1', 'methodDescription': 'Stream_Depth_Average'}, 'source': {'@sourceID': '1', 'organization': 'Para La Naturaleza', 'sourceDescription': 'Para La Naturaleza and National Science Foundation (Grant No. 1223882) sponsored this Citizen Science project about the hydrology of three streams in the Rio Grande de Manatí Watershed in Puerto Rico.', 'citation': 'Para La Naturaleza NSF'}, 'qualityControlLevel': {'@qualityControlLevelID': '1', 'qualityControlLevelCode': '1', 'definition': 'Quality controlled data'}}, {'variable': {'variableCode': {'@vocabulary': 'Para_La_Naturaleza', '@default': 'true', '@variableID': '2', '#text': 'Total_Flow'}, 'variableName': 'Discharge', 'valueType': 'Derived Value', 'dataType': 'Average', 'generalCategory': 'Hydrology', 'sampleMedium': 'Surface water', 'unit': {'unitName': 'cubic meters per second', 'unitType': 'Flow', 'unitAbbreviation': 'm^3/s', 'unitCode': '36'}, 'noDataValue': '-9999', 'timeScale': {'@isRegular': 'true', 'unit': {'unitName': 'cubic meters per second', 'unitType': 'Flow', 'unitAbbreviation': 'm^3/s', 'unitCode': '36'}, 'timeSupport': '1'}, 'speciation': 'Not Applicable'}, 'valueCount': '21', 'variableTimeInterval': {'@xsi:type': 'TimeIntervalType', 'beginDateTime': '2013-08-03T09:00:00', 'endDateTime': '2015-05-02T09:00:00', 'beginDateTimeUTC': '2013-08-03T05:00:00', 'endDateTimeUTC': '2015-05-02T05:00:00'}, 'method': {'@methodID': '2', 'methodDescription': 'Total_Flow'}, 'source': {'@sourceID': '1', 'organization': 'Para La Naturaleza', 'sourceDescription': 'Para La Naturaleza and National Science Foundation (Grant No. 1223882) sponsored this Citizen Science project about the hydrology of three streams in the Rio Grande de Manatí Watershed in Puerto Rico.', 'citation': 'Para La Naturaleza NSF'}, 'qualityControlLevel': {'@qualityControlLevelID': '1', 'qualityControlLevelCode': '1', 'definition': 'Quality controlled data'}}, {'variable': {'variableCode': {'@vocabulary': 'Para_La_Naturaleza', '@default': 'true', '@variableID': '3', '#text': 'Average_Stream_Velocity'}, 'variableName': 'Velocity', 'valueType': 'Derived Value', 'dataType': 'Average', 'generalCategory': 'Hydrology', 'sampleMedium': 'Surface water', 'unit': {'unitName': 'meters per second', 'unitType': 'Velocity', 'unitAbbreviation': 'm/s', 'unitCode': '119'}, 'noDataValue': '-9999', 'timeScale': {'@isRegular': 'true', 'unit': {'unitName': 'meters per second', 'unitType': 'Velocity', 'unitAbbreviation': 'm/s', 'unitCode': '119'}, 'timeSupport': '1'}, 'speciation': 'Not Applicable'}, 'valueCount': '21', 'variableTimeInterval': {'@xsi:type': 'TimeIntervalType', 'beginDateTime': '2013-08-03T09:00:00', 'endDateTime': '2015-05-02T09:00:00', 'beginDateTimeUTC': '2013-08-03T05:00:00', 'endDateTimeUTC': '2015-05-02T05:00:00'}, 'method': {'@methodID': '3', 'methodDescription': 'Average_Stream_Velocity'}, 'source': {'@sourceID': '1', 'organization': 'Para La Naturaleza', 'sourceDescription': 'Para La Naturaleza and National Science Foundation (Grant No. 1223882) sponsored this Citizen Science project about the hydrology of three streams in the Rio Grande de Manatí Watershed in Puerto Rico.', 'citation': 'Para La Naturaleza NSF'}, 'qualityControlLevel': {'@qualityControlLevelID': '1', 'qualityControlLevelCode': '1', 'definition': 'Quality controlled data'}}]}}}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU7hq7E-WM__",
        "colab_type": "text"
      },
      "source": [
        "# Get Time series from a specific variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqIqQ5X9WFpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## just change this for any of the variables above ##\n",
        "chosen_variable_name = 'Water depth, averaged'\n",
        "chosen_variable_index = info_site['variables_names'].index(chosen_variable_name)\n",
        "chosen_variable_code = info_site['variables_codes'][chosen_variable_index]\n",
        "chosen_variable_methodID = info_site['variables_methodsIDs'][chosen_variable_name]\n",
        "\n",
        "##now we will get the time frame for the time series of the variable, you can change it to any value in within later ##\n",
        "variabletimeSeriesInfo = info_site['variables_times_series_description'][chosen_variable_name]\n",
        "beginningTime= variabletimeSeriesInfo['beginDateTime'].split('T')[0]\n",
        "endingTime= variabletimeSeriesInfo['endDateTime'].split('T')[0]\n",
        "\n",
        "##create a dict for the variable values##\n",
        "chosen_variable_dict = {}\n",
        "chosen_variable_dict['code'] = chosen_variable_code\n",
        "chosen_variable_dict['startDate'] = beginningTime\n",
        "chosen_variable_dict['endDate'] = endingTime\n",
        "chosen_variable_dict['methodID'] = chosen_variable_methodID\n"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqJk0IQCW1GX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_values_graph_hs(chosen_site_dict,chosen_variable_dict):\n",
        "    return_obj={}\n",
        "    site_code =  chosen_site_dict['sitecode']\n",
        "    network = chosen_site_dict['network']\n",
        "    site_desc = network + ':' + site_code\n",
        "    code_variable = chosen_variable_dict['code']\n",
        "    start_date = chosen_variable_dict['startDate']\n",
        "    end_date = chosen_variable_dict['endDate']\n",
        "    actual_methodsID = chosen_variable_dict['methodID']\n",
        "\n",
        "    variable_desc = network + ':' + code_variable\n",
        "\n",
        "    client = Client(hs_url)  # Connect to the HydroServer endpoint\n",
        "\n",
        "\n",
        "    values = client.service.GetValues(\n",
        "        site_desc, variable_desc, start_date, end_date, \"\")\n",
        "    values_dict = xmltodict.parse(values)  # Converting xml to dict\n",
        "    values_json_object = json.dumps(values_dict)\n",
        "    values_json = json.loads(values_json_object)\n",
        "    times_series = {}\n",
        "    if 'timeSeriesResponse' in values_json:\n",
        "\n",
        "        times_series = values_json['timeSeriesResponse'][\n",
        "            'timeSeries']  # Timeseries object for the variable\n",
        "        if times_series['values'] is not None:\n",
        "\n",
        "            graph_json = {}  # json object that will be returned to the front end\n",
        "            graph_json[\"variable\"] = times_series['variable']['variableName']\n",
        "            graph_json[\"unit\"]=\"\"\n",
        "            if times_series['variable']['unit']['unitAbbreviation'] is not None:\n",
        "                graph_json[\"unit\"] = times_series[\n",
        "                    'variable']['unit']['unitAbbreviation']\n",
        "\n",
        "            graph_json[\"title\"] = times_series['variable']['variableName'] + \" (\" + graph_json[\"unit\"] + \") vs Time\"\n",
        "            for j in times_series['values']:  # Parsing the timeseries\n",
        "                data_values = []\n",
        "                data_values2 = []\n",
        "                if j == \"value\":\n",
        "                    if type(times_series['values']['value']) is list:\n",
        "\n",
        "                        count = 0\n",
        "                        for k in times_series['values']['value']:\n",
        "                            return_obj['k']= k\n",
        "\n",
        "                            try:\n",
        "                                if k['@methodCode'] == actual_methodsID:\n",
        "                                    count = count + 1\n",
        "                                    time = k['@dateTimeUTC']\n",
        "                                    time1 = time.replace(\"T\", \"-\")\n",
        "                                    time_split = time1.split(\"-\")\n",
        "                                    year = int(time_split[0])\n",
        "                                    month = int(time_split[1])\n",
        "                                    day = int(time_split[2])\n",
        "                                    hour_minute = time_split[3].split(\":\")\n",
        "                                    hour = int(hour_minute[0])\n",
        "                                    minute = int(hour_minute[1])\n",
        "                                    value = float(str(k['#text']))\n",
        "                                    date_string = datetime(\n",
        "                                        year, month, day, hour, minute)\n",
        "\n",
        "                                    date_string_converted = date_string.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                                    data_values2.append([date_string_converted,value])\n",
        "                                    data_values2.sort()\n",
        "                                    time_stamp = calendar.timegm(\n",
        "                                        date_string.utctimetuple()) * 1000\n",
        "                                    data_values.append([time_stamp, value])\n",
        "                                    data_values.sort()\n",
        "                                graph_json[\"values2\"] = data_values2\n",
        "                                graph_json[\"count\"] = count\n",
        "                            except KeyError:  # The Key Error kicks in when there is only one timeseries\n",
        "                                count = count + 1\n",
        "                                time = k['@dateTimeUTC']\n",
        "                                time1 = time.replace(\"T\", \"-\")\n",
        "                                time_split = time1.split(\"-\")\n",
        "                                year = int(time_split[0])\n",
        "                                month = int(time_split[1])\n",
        "                                day = int(time_split[2])\n",
        "                                hour_minute = time_split[3].split(\":\")\n",
        "                                hour = int(hour_minute[0])\n",
        "                                minute = int(hour_minute[1])\n",
        "                                value = float(str(k['#text']))\n",
        "                                date_string = datetime(\n",
        "                                    year, month, day, hour, minute)\n",
        "                                data_values2.append([date_string,value])\n",
        "                                data_values2.sort()\n",
        "                                time_stamp = calendar.timegm(\n",
        "                                    date_string.utctimetuple()) * 1000\n",
        "                                data_values.append([time_stamp, value])\n",
        "                                data_values.sort()\n",
        "                            graph_json[\"values\"] = data_values2\n",
        "                            graph_json[\"count\"] = count\n",
        "                            return_obj['graphs']=graph_json\n",
        "\n",
        "                    else:  # The else statement is executed is there is only one value in the timeseries\n",
        "                        try:\n",
        "                            if times_series['values']['value']['@methodCode'] == actual_methodsID:\n",
        "                                time = times_series['values'][\n",
        "                                    'value']['@dateTimeUTC']\n",
        "                                time1 = time.replace(\"T\", \"-\")\n",
        "                                time_split = time1.split(\"-\")\n",
        "                                year = int(time_split[0])\n",
        "                                month = int(time_split[1])\n",
        "                                day = int(time_split[2])\n",
        "                                hour_minute = time_split[3].split(\":\")\n",
        "                                hour = int(hour_minute[0])\n",
        "                                minute = int(hour_minute[1])\n",
        "                                value = float(\n",
        "                                    str(times_series['values']['value']['#text']))\n",
        "\n",
        "                                date_string = datetime(\n",
        "                                    year, month, day, hour, minute)\n",
        "\n",
        "                                data_values2.append([date_string,value])\n",
        "                                data_values2.sort()\n",
        "                                time_stamp = calendar.timegm(\n",
        "                                    date_string.utctimetuple()) * 1000\n",
        "                                data_values.append([time_stamp, value])\n",
        "                                data_values.sort()\n",
        "                                graph_json[\"values2\"] = data_values2\n",
        "\n",
        "                                # graph_json[\"values\"] = data_values\n",
        "                                graph_json[\"count\"] = 1\n",
        "                                return_obj['graphs']=graph_json\n",
        "\n",
        "                        except KeyError:\n",
        "                            time = times_series['values'][\n",
        "                                'value']['@dateTimeUTC']\n",
        "                            time1 = time.replace(\"T\", \"-\")\n",
        "                            time_split = time1.split(\"-\")\n",
        "                            year = int(time_split[0])\n",
        "                            month = int(time_split[1])\n",
        "                            day = int(time_split[2])\n",
        "                            hour_minute = time_split[3].split(\":\")\n",
        "                            hour = int(hour_minute[0])\n",
        "                            minute = int(hour_minute[1])\n",
        "                            value = float(\n",
        "                                str(times_series['values']['value']['#text']))\n",
        "                            date_string = datetime(\n",
        "                                year, month, day, hour, minute)\n",
        "\n",
        "                            time_stamp = calendar.timegm(\n",
        "                                date_string.utctimetuple()) * 1000\n",
        "                            data_values.append([time_stamp, value])\n",
        "                            data_values.sort()\n",
        "\n",
        "                            data_values2.append([date_string,value])\n",
        "                            data_values2.sort()\n",
        "                            graph_json[\"values\"] = data_values2\n",
        "                            graph_json[\"count\"] = 1\n",
        "                            return_obj['graphs']=graph_json\n",
        "\n",
        "    else:\n",
        "        times_series = values_json['wml1:timeSeriesResponse'][\n",
        "            'wml1:timeSeries']  # Timeseries object for the variable\n",
        "\n",
        "        return_obj['values'] = times_series\n",
        "        if times_series['wml1:values'] is not None:\n",
        "\n",
        "\n",
        "            return_obj['values'] = times_series\n",
        "\n",
        "            graph_json = {}  # json object that will be returned to the front end\n",
        "            graph_json[\"variable\"] = times_series['wml1:variable']['wml1:variableName']\n",
        "            graph_json[\"unit\"]=\"\"\n",
        "            if times_series['wml1:variable']['wml1:unit']['wml1:unitAbbreviation'] is not None:\n",
        "                graph_json[\"unit\"] = times_series[\n",
        "                    'wml1:variable']['wml1:unit']['wml1:unitAbbreviation']\n",
        "\n",
        "\n",
        "            graph_json[\"title\"] = times_series['wml1:variable']['wml1:variableName'] + \" (\" + graph_json[\"unit\"] + \") vs Time\"\n",
        "            for j in times_series['wml1:values']:  # Parsing the timeseries\n",
        "                data_values = []\n",
        "                data_values2 = []\n",
        "                if j == \"wml1:value\":\n",
        "                    if type(times_series['wml1:values']['wml1:value']) is list:\n",
        "                        count = 0\n",
        "                        for k in times_series['wml1:values']['wml1:value']:\n",
        "                            return_obj['k']= k\n",
        "\n",
        "                            try:\n",
        "\n",
        "                                if k['@methodCode'] == actual_methodsID:\n",
        "                                    count = count + 1\n",
        "                                    time = k['@dateTimeUTC']\n",
        "                                    time1 = time.replace(\"T\", \"-\")\n",
        "\n",
        "\n",
        "                                    time_split = time1.split(\"-\")\n",
        "                                    year = int(time_split[0])\n",
        "                                    month = int(time_split[1])\n",
        "                                    day = int(time_split[2])\n",
        "                                    hour_minute = time_split[3].split(\":\")\n",
        "                                    hour = int(hour_minute[0])\n",
        "                                    minute = int(hour_minute[1])\n",
        "                                    value = float(str(k['#text']))\n",
        "                                    date_string = datetime(\n",
        "                                        year, month, day, hour, minute)\n",
        "\n",
        "                                    date_string_converted = date_string.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                                    data_values2.append([date_string_converted,value])\n",
        "                                    data_values2.sort()\n",
        "                                    time_stamp = calendar.timegm(\n",
        "                                        date_string.utctimetuple()) * 1000\n",
        "                                    data_values.append([time_stamp, value])\n",
        "                                    data_values.sort()\n",
        "                                graph_json[\"values2\"] = data_values2\n",
        "                                graph_json[\"count\"] = count\n",
        "                            except KeyError:  # The Key Error kicks in when there is only one timeseries\n",
        "                                print(\"The Key Error kicks in because there was only one timespace\")\n",
        "                                count = count + 1\n",
        "                                time = k['@dateTimeUTC']\n",
        "                                time1 = time.replace(\"T\", \"-\")\n",
        "                                time_split = time1.split(\"-\")\n",
        "                                year = int(time_split[0])\n",
        "                                month = int(time_split[1])\n",
        "                                day = int(time_split[2])\n",
        "                                hour_minute = time_split[3].split(\":\")\n",
        "                                hour = int(hour_minute[0])\n",
        "                                minute = int(hour_minute[1])\n",
        "                                value = float(str(k['#text']))\n",
        "                                date_string = datetime(\n",
        "                                    year, month, day, hour, minute)\n",
        "                                # print(date_string)\n",
        "                                data_values2.append([date_string,value])\n",
        "                                data_values2.sort()\n",
        "                                time_stamp = calendar.timegm(\n",
        "                                    date_string.utctimetuple()) * 1000\n",
        "                                data_values.append([time_stamp, value])\n",
        "                                data_values.sort()\n",
        "                            graph_json[\"values\"] = data_values2\n",
        "                            graph_json[\"count\"] = count\n",
        "                            return_obj['graphs']=graph_json\n",
        "\n",
        "                    else:  # The else statement is executed is there is only one value in the timeseries\n",
        "                        try:\n",
        "                            if times_series['values']['value']['@methodCode'] == actual_methodsID:\n",
        "                                time = times_series['values'][\n",
        "                                    'value']['@dateTimeUTC']\n",
        "                                time1 = time.replace(\"T\", \"-\")\n",
        "                                time_split = time1.split(\"-\")\n",
        "                                year = int(time_split[0])\n",
        "                                month = int(time_split[1])\n",
        "                                day = int(time_split[2])\n",
        "                                hour_minute = time_split[3].split(\":\")\n",
        "                                hour = int(hour_minute[0])\n",
        "                                minute = int(hour_minute[1])\n",
        "                                value = float(\n",
        "                                    str(times_series['values']['value']['#text']))\n",
        "\n",
        "                                date_string = datetime(\n",
        "                                    year, month, day, hour, minute)\n",
        "                                data_values2.append([date_string,value])\n",
        "                                data_values2.sort()\n",
        "                                time_stamp = calendar.timegm(\n",
        "                                    date_string.utctimetuple()) * 1000\n",
        "                                data_values.append([time_stamp, value])\n",
        "                                data_values.sort()\n",
        "                                graph_json[\"values2\"] = data_values2\n",
        "                                graph_json[\"count\"] = 1\n",
        "                                return_obj['graphs']=graph_json\n",
        "\n",
        "                        except KeyError:\n",
        "                            time = times_series['values'][\n",
        "                                'value']['@dateTimeUTC']\n",
        "                            time1 = time.replace(\"T\", \"-\")\n",
        "                            time_split = time1.split(\"-\")\n",
        "                            year = int(time_split[0])\n",
        "                            month = int(time_split[1])\n",
        "                            day = int(time_split[2])\n",
        "                            hour_minute = time_split[3].split(\":\")\n",
        "                            hour = int(hour_minute[0])\n",
        "                            minute = int(hour_minute[1])\n",
        "                            value = float(\n",
        "                                str(times_series['values']['value']['#text']))\n",
        "                            date_string = datetime(\n",
        "                                year, month, day, hour, minute)\n",
        "                            time_stamp = calendar.timegm(\n",
        "                                date_string.utctimetuple()) * 1000\n",
        "                            data_values.append([time_stamp, value])\n",
        "                            data_values.sort()\n",
        "\n",
        "                            data_values2.append([date_string,value])\n",
        "                            data_values2.sort()\n",
        "                            graph_json[\"values\"] = data_values2\n",
        "                            graph_json[\"count\"] = 1\n",
        "                            return_obj['graphs']=graph_json\n",
        "    ##INTERPOLATION\n",
        "    ##UNCOMMENT THESE LINES FOR MEAN INTERPOLATION\n",
        "\n",
        "    # time_pd, values_pd = zip(*graph_json[\"values2\"])\n",
        "    # pds={}\n",
        "    # pds['time'] = time_pd\n",
        "    # pds['value'] = values_pd\n",
        "    # df_interpolation= pd.DataFrame(pds,columns = [\"time\",\"value\"])\n",
        "    # df_interpolation2= pd.DataFrame(pds,columns = [\"time\",\"value\"])\n",
        "    # df_interpolation.loc[df_interpolation.value < 0] = np.NaN\n",
        "    # df_interpolation.replace(0, np.nan, inplace=True)\n",
        "    # df_interpolation['time'] = pd.to_datetime(df_interpolation['time'])\n",
        "    # df_interpolation = df_interpolation.set_index('time').resample('D').mean()\n",
        "    # df_interpolation['value'] = df_interpolation['value'].interpolate()\n",
        "    # df_interpolation.reset_index(level=0, inplace=True)\n",
        "    # listVals = df_interpolation['value'].to_list()\n",
        "    # listTimes = df_interpolation['time'].to_list()\n",
        "    # dataInterpolated = []\n",
        "    # for t,v in zip(listTimes,listVals):\n",
        "    #     dataInterpolated.append([t,v])\n",
        "    # graph_json['interpolation']=dataInterpolated\n",
        "\n",
        "    return return_obj"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrvBW9J0c_Jv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "346ec5a8-fb7a-462b-ad43-f15b8e8f2239"
      },
      "source": [
        "##Get the time series\n",
        "variable_object = get_values_graph_hs(chosen_site_dict,chosen_variable_dict)['graphs']\n",
        "timeStamps=[]\n",
        "valuesTimeSeries = []\n",
        "for index in variable_object['values']:\n",
        "  timeStamps.append(index[0])\n",
        "  valuesTimeSeries.append(index[1])\n",
        "\n",
        "##PLOT THE TIME SERIES\n",
        "\n",
        "fig = go.Figure(data=go.Scatter(x=timeStamps, y=valuesTimeSeries))\n",
        "# Edit the layout\n",
        "fig.update_layout(title = variable_object ['title'],\n",
        "                   xaxis_title ='Time',\n",
        "                   yaxis_title = variable_object ['unit'])\n",
        "fig.show()\n"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"8bbba3f0-b862-4730-8875-67129240b757\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"8bbba3f0-b862-4730-8875-67129240b757\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '8bbba3f0-b862-4730-8875-67129240b757',\n",
              "                        [{\"type\": \"scatter\", \"x\": [\"2013-08-03 05:00:00\", \"2013-09-07 05:00:00\", \"2013-10-05 05:00:00\", \"2013-11-02 05:00:00\", \"2013-12-07 05:00:00\", \"2014-01-11 05:00:00\", \"2014-02-01 05:00:00\", \"2014-03-01 05:00:00\", \"2014-04-05 05:00:00\", \"2014-05-03 05:00:00\", \"2014-06-07 05:00:00\", \"2014-07-05 05:00:00\", \"2014-09-06 05:00:00\", \"2014-10-04 05:00:00\", \"2014-11-01 05:00:00\", \"2014-12-06 05:00:00\", \"2015-01-03 05:00:00\", \"2015-02-07 05:00:00\", \"2015-03-07 05:00:00\", \"2015-04-04 05:00:00\"], \"y\": [0.1815, 0.187, 0.226, 0.1535, 0.231, 0.15525, 0.124875, 0.0, 0.1145, 0.0877, 0.0, 0.09375, 0.12175, 0.10325, 0.1693, 0.187, 0.1285, 0.125, 0.159, 0.14]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Water depth, averaged (m) vs Time\"}, \"xaxis\": {\"title\": {\"text\": \"Time\"}}, \"yaxis\": {\"title\": {\"text\": \"m\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8bbba3f0-b862-4730-8875-67129240b757');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}
